# Unlocking the Power of LLMs for Customizable Problem-Solving

By the end of this workshop, participants will gain hands-on experience in harnessing the power of Large Language Models (LLMs) using Llama and Langchain to create customizable applications that can solve real-world problems. Through interactive demonstrations, participants will learn how to leverage LLAMA's capabilities to build innovative applications. 

### Prior knowledge:
* **Intermediate Python**: You need to know how to setup a virtual environment, install the required packages, and jupyter-lab.
* **Git/GitHub**: The content and base files for this workshop are hosted in GitHub, you need to able to clone the repository.
* **LLM Agents**: You should have played around with Chat-GPT or any other LLM Agent in the past.
* **Basic SQL**: One demo showcases how to translate natural language to SQL.

### Technical requirements:
* Laptop with GPU capabilities and 10GB of disk space.
* Python 3.9, pip, and virtualenvironment.
* Git/GitHub Client.
* A Python IDE.

### Pre-Workshop Requisites
Go over the [pre-workshop requisites tutorial](./pre_reqs/pre-requisites.md) to prepare you system for the workshop. It requires to install Ollama, and download ~5GB of data, therefore it is better to do it before the workshop. 

### Agenda
*Note:* If time permits, we will cover all four interactive use cases during the workshop. However, if we are short on time, some demos will be assigned as take-home exercises for participants to complete on their own. 

0. Pre-Workshop Requisites Check
1. Introduction
    1. LLMs and LLaMa Overview
    2. What is RAG?
    3. LLM Agent Architecture
    4. Security and Privacy considerations
2. Interactive Session
    1. *Langchain Basics:* Introduction to langchain. Inspect each block, make changes, and see how it affects the outputs.
    2. *Basic Agent:* Dive into a Jupyter notebook and get familiar with a basic agent. 
    3. *Data Retrieval:* Learn how to extend the basic agent to connect to a database for data retrieval. Discover how this approach can be applied to fetch information from third-party APIs or RESTful endpoints.
    4. *GenAI Model Chaining:* Witness the power of chaining GenAI models together. See how Llama can create prompts for diffusion models to generate animations.
    5. *Web Application:* Take an LLM agent from a notebook and transform it into a Flask application. Experience the process of bringing your agent to life on the web.
4. Final Notes
    1. More examples of industry applications.
    2. Instructions to deploy on cloud.
    3. Instructions to deploy on premises.

### Presenters bio

**Sunandan Barman** has been working as a tech lead at Meta since 2017, guiding a team of six engineers to enhance the performance and scalability of the ML data platform for App Ads, ultimately impacting Meta's primary revenue sources. Sunandan is highly experienced backend developer with more than a decade of expertise in crafting scalable and distributed systems capable of handling immense loads

**Cesar Gama** has over a decade of experience working in tech companies in Silicon Valley. He currently works at Meta as a technical lead, where he focuses on building reliable machine learning systems. He has also worked closely with cross-functional teams to identify and build monetization products in the GenAI space.

### License

