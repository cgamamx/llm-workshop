# Unlocking the Power of LLMs for Customizable Problem-Solving

This workshop covers the use of LLM agents ( using Llama ) and how to integrate them into different real life applications. Participants will get hands-on experience with Llama by learning how to extend a basic agent to connect to a database for data retrieval & how to chain GenAI models together to generate animations. The workshop will also cover security and privacy considerations when working with LLM agents. 

### Prior knowledge:
* **Intermediate Python**: You need to know how to setup a virtual environment, install the required packages, and jupyter-lab.
* **Git/GitHub**: The content and base files for this workshop are hosted in GitHub, you need to able to clone the repository.
* **LLM Agents**: You should have played around with Chat-GPT, Llama or any other AI Agent in the past.
* **Basic SQL**: One demo showcases how to translate natural language to SQL.

### Technical requirements:
* Laptop with GPU capabilities and 10GB of disk space.
* Python 3.9, pip, and virtualenvironment.
* Git/GitHub Client.
* A Python IDE.

### Pre-Workshop Requisites
Go over the pre-workshop requisites tutorial to prepare you system for the workshop. It requires to install Ollama, and download ~5GB of data, therefore it is better to do it before the workshop. 

### Agenda
*Note:* If time permits, we will cover all four interactive use cases during the workshop. However, if we are short on time, demos #3 and #4 will be assigned as take-home exercises for participants to complete on their own. 

0. Pre-Workshop Requisites Check
1. Introduction
    1. LLMs and LLaMa Overview
    2. What is RAG?
    3. LLM Agent Architecture
    4. Security and Privacy considerations
2. Interactive Session
    1. *Basic Agent:* Dive into a Jupyter notebook and get familiar with a basic agent. Inspect each block, make changes, and see how it affects the agent's behavior.
    2. *Data Retrieval:* Learn how to extend the basic agent to connect to a database for data retrieval. Discover how this approach can be applied to fetch information from third-party APIs or RESTful endpoints.
    3. *GenAI Model Chaining:* Witness the power of chaining GenAI models together. See how Llama can create prompts for diffusion models to generate animations.
    4. *Web Application:* Take an LLM agent from a notebook and transform it into a Flask application. Experience the process of bringing your agent to life on the web.
3. Final Notes
    1. More examples of industry applications.
    2. Instructions to deploy on cloud.
    3. Instructions to deploy on premises.

### Presenters bio

**Sunandan Barman** has been working as a tech lead at Meta since 2017, guiding a team of six engineers to enhance the performance and scalability of the ML data platform for App Ads, ultimately impacting Meta's primary revenue sources. Sunandan is highly experienced backend developer with more than a decade of expertise in crafting scalable and distributed systems capable of handling immense loads

**Cesar Gama** has over a decade of experience working in tech companies in Silicon Valley. He currently works at Meta as a technical lead, where he focuses on building reliable machine learning systems. He has also worked closely with cross-functional teams to identify and build monetization products in the GenAI space.
